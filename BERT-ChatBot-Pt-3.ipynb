{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NoNQ-6MQ2hQq",
        "outputId": "56aa06c3-9f39-4948-ccb9-d6ea7dad439d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n"
          ]
        }
      ],
      "source": [
        "pip install PyPDF2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "id": "9SURM9k9rlNJ",
        "outputId": "04e6c221-3956-41d4-b274-8cf8ec47829a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at KB/bert-base-swedish-cased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hej! Jag är en chatbot som kan hjälpa dig med information från en textfil. Fråga mig vad som helst (eller skriv 'avsluta' för att sluta).\n",
            "Ange din fråga: Vem bär ansvaret för att säkerställa att kompetenskravsspecifikationen för Lärare uppfylls?\n",
            "Svar: \n",
            "Ange din fråga: Vem bär ansvaret för att säkerställa att kompetenskravsspecifikationen för Lärare uppfylls?\n",
            "Svar: \n",
            "Ange din fråga: ansvaret för att säkerställa\n",
            "Svar: \n",
            "Ange din fråga: kompetenskravsspecifikationen \n",
            "Svar: \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-d614317bbb33>\u001b[0m in \u001b[0;36m<cell line: 80>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m     \u001b[0muser_question\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Ange din fråga: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0muser_question\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'avsluta'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import re\n",
        "from transformers import BertTokenizer, BertForQuestionAnswering\n",
        "import torch\n",
        "\n",
        "# Initialize the BERT model and tokenizer\n",
        "model = BertForQuestionAnswering.from_pretrained('KB/bert-base-swedish-cased')\n",
        "tokenizer = BertTokenizer.from_pretrained('KB/bert-base-swedish-cased')\n",
        "\n",
        "def extract_text_content(text_path, encodings=['utf-8', 'ISO-8859-1', 'Windows-1252']):\n",
        "    for encoding in encodings:\n",
        "        try:\n",
        "            with open(text_path, 'r', encoding=encoding) as file:\n",
        "                all_text = file.read()\n",
        "            return all_text\n",
        "        except UnicodeDecodeError:\n",
        "            continue\n",
        "    raise ValueError(\"Unable to decode the text using any of the specified encodings: {}\".format(encodings))\n",
        "\n",
        "\n",
        "def get_context_sentences(text, query, window_size=1):\n",
        "    sentences = re.split(r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?)\\s', text)\n",
        "    query_sentences = []\n",
        "\n",
        "    for idx, sentence in enumerate(sentences):\n",
        "        if query.lower() in sentence.lower():\n",
        "            start_idx = max(0, idx - window_size)\n",
        "            end_idx = min(len(sentences), idx + window_size + 1)\n",
        "            context = ' '.join(sentences[start_idx:end_idx])\n",
        "            query_sentences.append(context)\n",
        "\n",
        "            # Retrieve words before each new line\n",
        "            lines = re.findall(r'(.+?)(?:\\n|$)', context, re.DOTALL)\n",
        "            for line in lines[:-1]:  # Exclude the last line\n",
        "                query_sentences.append(line.strip())\n",
        "\n",
        "    return query_sentences\n",
        "\n",
        "def generate_answer(user_question, text_content):\n",
        "    context_sentences = get_context_sentences(text_content, user_question, window_size=1)\n",
        "    answers = []\n",
        "\n",
        "    for sentence in context_sentences:\n",
        "        inputs = tokenizer.encode_plus(user_question, sentence, add_special_tokens=True, return_tensors=\"pt\", max_length=512, truncation=True)\n",
        "\n",
        "        # Get the output from the BERT model\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "\n",
        "        answer_start_scores = outputs.start_logits\n",
        "        answer_end_scores = outputs.end_logits\n",
        "\n",
        "        answer_start = torch.argmax(answer_start_scores)\n",
        "        answer_end = torch.argmax(answer_end_scores) + 1\n",
        "\n",
        "        answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(inputs['input_ids'][0][answer_start:answer_end]))\n",
        "        answers.append(answer)\n",
        "\n",
        "    return ' '.join(answers)\n",
        "\n",
        "def create_json(question, answer, context):\n",
        "    return {\n",
        "        \"Fråga\": question,\n",
        "        \"Svar\": answer,\n",
        "        \"Kontext\": context\n",
        "    }\n",
        "\n",
        "# Load existing data from output.json if it exists\n",
        "try:\n",
        "    with open('output.json', 'r', encoding='utf-8') as json_file:\n",
        "        data = json.load(json_file)\n",
        "except FileNotFoundError:\n",
        "    data = []\n",
        "\n",
        "text_sökväg = 'TDOK_2020-0216.pdf'  # Replace with your text file path\n",
        "text_innehåll = extract_text_content(text_sökväg)\n",
        "\n",
        "print(\"Hej! Jag är en chatbot som kan hjälpa dig med information från en textfil. Fråga mig vad som helst (eller skriv 'avsluta' för att sluta).\")\n",
        "\n",
        "while True:\n",
        "    user_question = input(\"Ange din fråga: \")\n",
        "\n",
        "    if user_question.lower() == 'avsluta':\n",
        "        print(\"Tack för att du chattade med mig. Adjö!\")\n",
        "        break\n",
        "\n",
        "    genererat_svar = generate_answer(user_question, text_innehåll)\n",
        "    print(\"Svar:\", genererat_svar)\n",
        "\n",
        "    # Create JSON data (optional)\n",
        "    json_data = create_json(user_question, genererat_svar, text_innehåll)\n",
        "    data.append(json_data)\n",
        "\n",
        "# Save data to output.json\n",
        "with open('output.json', 'w', encoding='utf-8') as json_file:\n",
        "    json.dump(data, json_file, ensure_ascii=False, indent=2)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import re\n",
        "from transformers import BertTokenizer, BertForQuestionAnswering\n",
        "import torch\n",
        "\n",
        "# Initialize the BERT model and tokenizer\n",
        "model = BertForQuestionAnswering.from_pretrained('KB/bert-base-swedish-cased')\n",
        "tokenizer = BertTokenizer.from_pretrained('KB/bert-base-swedish-cased')\n",
        "\n",
        "def extract_text_content(text_path, encodings=['utf-8', 'ISO-8859-1', 'Windows-1252']):\n",
        "    for encoding in encodings:\n",
        "        try:\n",
        "            with open(text_path, 'r', encoding=encoding) as file:\n",
        "                all_text = file.read()\n",
        "            return all_text\n",
        "        except UnicodeDecodeError:\n",
        "            continue\n",
        "    raise ValueError(\"Unable to decode the text using any of the specified encodings: {}\".format(encodings))\n",
        "\n",
        "\n",
        "def generate_answer(user_question, text_content):\n",
        "    inputs = tokenizer.encode_plus(user_question, text_content, add_special_tokens=True, return_tensors=\"pt\", max_length=512, truncation='only_second')\n",
        "\n",
        "    # Get the output from the BERT model\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "    answer_start_scores = outputs.start_logits\n",
        "    answer_end_scores = outputs.end_logits\n",
        "\n",
        "    answer_start = torch.argmax(answer_start_scores)\n",
        "    answer_end = torch.argmax(answer_end_scores) + 1\n",
        "\n",
        "    answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(inputs['input_ids'][0][answer_start:answer_end]))\n",
        "\n",
        "    return answer\n",
        "\n",
        "\n",
        "text_path = 'TDOK_2015-0430.pdf'  # Replace with your text file path\n",
        "text_content = extract_text_content(text_path)\n",
        "\n",
        "print(\"Hej! Jag är en chatbot som kan hjälpa dig med information från en textfil. Fråga mig vad som helst (eller skriv 'avsluta' för att sluta).\")\n",
        "\n",
        "while True:\n",
        "    user_question = input(\"Ange din fråga: \")\n",
        "\n",
        "    if user_question.lower() == 'avsluta':\n",
        "        print(\"Tack för att du chattade med mig. Adjö!\")\n",
        "        break\n",
        "\n",
        "    generated_answer = generate_answer(user_question, text_content)\n",
        "    print(\"Svar:\", generated_answer)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 498
        },
        "id": "zNfgNT9VLyXs",
        "outputId": "16411b5f-ce82-4060-977e-982396b63061"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at KB/bert-base-swedish-cased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hej! Jag är en chatbot som kan hjälpa dig med information från en textfil. Fråga mig vad som helst (eller skriv 'avsluta' för att sluta).\n",
            "Ange din fråga: TTJ\n",
            "Svar: ##g ) / Creator ( Aspose Ltd . ) / Subject ( \\ 376 \\ 377 \\ 000P \\ 000r \\ 000o \\ 000v \\ 000k \\ 000 \\ 366 \\ 000r \\ 000n \\ 000i \\ 000n \\ 000g ) / Producer ( Aspose . Pdf for . NET 8 . 5 . 0 ) > > endobj 2 0 obj < < / OutputIntents [ < < / Info ( sRGB IEC61966 - 2 . 1\n",
            "Ange din fråga: vad ar TTJ?\n",
            "Svar: ##g ) / Creator ( Aspose Ltd . ) / Subject ( \\ 376 \\ 377 \\ 000P \\ 000r \\ 000o \\ 000v \\ 000k \\ 000 \\ 366 \\ 000r \\ 000n \\ 000i \\ 000n \\ 000g ) / Producer ( Aspose . Pdf for . NET 8 . 5 . 0 ) > > endobj 2 0 obj < < / OutputIntents [ < < / Info ( sRGB IEC61966 - 2 . 1\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-0c6018fe4386>\u001b[0m in \u001b[0;36m<cell line: 44>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0muser_question\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Ange din fråga: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0muser_question\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'avsluta'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}